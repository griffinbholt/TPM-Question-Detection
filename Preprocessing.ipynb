{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "\n",
    "from os import listdir, system, makedirs\n",
    "from os.path import isfile, join, exists\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_millisec(time_str):\n",
    "    h, m, s = time_str.split(':')\n",
    "    return (int(h) * 3600 + int(m) * 60 + int(s)) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_MTC_DATA = '/srv/mtc_data'\n",
    "PATH_TO_ANNOTATIONS = join(PATH_TO_MTC_DATA, 'annotations')\n",
    "PATH_TO_VIDEOS = join(PATH_TO_MTC_DATA, 'mtc-videos-TRC')\n",
    "PATH_TO_AUDIO = join(PATH_TO_MTC_DATA, 'tpm-f2020-project/mtc-audio-TRC')\n",
    "PATH_TO_SPLIT_AUDIO = join(PATH_TO_MTC_DATA, 'tpm-f2020-project/mtc-split-wav-files')\n",
    "\n",
    "SPLIT_AUDIO_DIR_CONVENTION = 'length-{}-period-{}'\n",
    "DATA_POINT_DIR_CONVENTION = 'starttime-{}-title-{}'\n",
    "SPLIT_AUDIO_FILE_CONVENTION = 'last-{}.wav'\n",
    "QUESTION_TRUTH_LABELS_CONVENTION = 'tpm-f2020-project/length-{}-period-{}-question_truth_labels.pkl'\n",
    "\n",
    "XML_TAG_NAME = 'video'\n",
    "FILENAME_ATTR = 'filename'\n",
    "QUESTION_TRUTH_ATTR = 'question_truth'\n",
    "\n",
    "MP4_FORMAT = 'mp4'\n",
    "WAV_FORMAT = 'wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_LENGTHS = [5000] # milliseconds\n",
    "CLIP_PERIODS = [250, 500] # milliseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of annotation XML files\n",
    "annotation_files = [join(PATH_TO_ANNOTATIONS, xml_file) for xml_file in listdir(PATH_TO_ANNOTATIONS) if isfile(join(PATH_TO_ANNOTATIONS, xml_file))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse each XML file\n",
    "annotations = list(map(minidom.parse, annotation_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the files names and the question_truth lists for each of the .mp4 videos from the XML files\n",
    "mp4_filepaths, wav_files, wav_filepaths = [], [], []\n",
    "question_times = {}\n",
    "for annotation in annotations:\n",
    "    video_elem = annotation.getElementsByTagName(XML_TAG_NAME)[0]\n",
    "    mp4_filename = video_elem.attributes[FILENAME_ATTR].value.replace(MP4_FORMAT.upper(), MP4_FORMAT)\n",
    "    wav_file = mp4_filename.replace(MP4_FORMAT, WAV_FORMAT)\n",
    "    mp4_filename = join(PATH_TO_VIDEOS, mp4_filename)\n",
    "\n",
    "    if mp4_filename not in mp4_filepaths:\n",
    "        mp4_filepaths.append(mp4_filename)\n",
    "\n",
    "        wav_files.append(wav_file)\n",
    "        wav_filepaths.append(join(PATH_TO_AUDIO, wav_file))\n",
    "\n",
    "    question_time_vector = list(map(get_millisec, eval(video_elem.attributes[QUESTION_TRUTH_ATTR].value)))\n",
    "\n",
    "    if wav_file in question_times:\n",
    "        question_times[wav_file].extend(question_time_vector)\n",
    "        question_times[wav_file].sort()\n",
    "    else:\n",
    "        question_times[wav_file] = question_time_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the audio from each .mp4 video and save it as a .wav file\n",
    "for i in range(len(mp4_filepaths)):\n",
    "    system('ffmpeg -i {} -vn {}'.format(mp4_filepaths[i], wav_filepaths[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_truth_labels = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each combination of clip lengths & clip periods\n",
    "for clip_length in CLIP_LENGTHS:\n",
    "    for clip_period in CLIP_PERIODS:\n",
    "        question_truth_labels = {}\n",
    "\n",
    "        # Create a folder for the group of .wav files corresponding to that clip length & clip period, if it doesn't exist\n",
    "        split_audio_dir = join(PATH_TO_SPLIT_AUDIO, SPLIT_AUDIO_DIR_CONVENTION.format(clip_length, clip_period))\n",
    "        if not exists(split_audio_dir):\n",
    "            makedirs(split_audio_dir)\n",
    "\n",
    "        # Split each of the main .wav files into rolling windows of clip_length, every clip_period\n",
    "        for i in range(len(wav_files)):\n",
    "            # Get the full audio .wav file\n",
    "            full_audio = AudioSegment.from_wav(wav_filepaths[i])\n",
    "            question_time_vector = question_times[wav_files[i]]\n",
    "            \n",
    "            t1 = 0\n",
    "            while t1 < len(full_audio):\n",
    "                t2 = t1 + clip_length\n",
    "\n",
    "                data_point_dir = join(split_audio_dir, DATA_POINT_DIR_CONVENTION.format(t1, wav_files[i].replace('.wav', '')))\n",
    "                makedirs(data_point_dir)\n",
    "\n",
    "                full_clip_filename = join(data_point_dir, SPLIT_AUDIO_FILE_CONVENTION.format(0))\n",
    "                last_500_filename = join(data_point_dir, SPLIT_AUDIO_FILE_CONVENTION.format(500)) \n",
    "                last_200_filename = join(data_point_dir, SPLIT_AUDIO_FILE_CONVENTION.format(200)) \n",
    "\n",
    "                full_clip = full_audio[t1:t2]\n",
    "                \n",
    "                t_500 = t2 - 500\n",
    "                t_500 = t_500 if t_500 > t1 else t1\n",
    "                \n",
    "                t_200 = t2 - 200\n",
    "                t_200 = t_200 if t_200 > t1 else t1\n",
    "\n",
    "                full_clip.export(full_clip_filename, format=WAV_FORMAT)\n",
    "                full_clip[t_500:t2].export(last_500_filename, format=WAV_FORMAT)\n",
    "                full_clip[t_200:t2].export(last_200_filename, format=WAV_FORMAT)\n",
    "\n",
    "                question_truth_labels[data_point_dir] = False\n",
    "                for time in question_time_vector:\n",
    "                    if time > t1 and time < t2:\n",
    "                        question_truth_labels[data_point_dir] = True\n",
    "                        break\n",
    "\n",
    "                t1 += clip_period\n",
    "            \n",
    "        f = open(join(PATH_TO_MTC_DATA, QUESTION_TRUTH_LABELS_CONVENTION.format(clip_length, clip_period)), \"wb\")\n",
    "        pickle.dump(question_truth_labels,f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Sys)",
   "language": "python",
   "name": "python3-system"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
