{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, system, makedirs\n",
    "from os.path import isfile, join, exists\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import parselmouth as pm\n",
    "from tysums import *\n",
    "from henrys import *\n",
    "\n",
    "clip_length = 5000\n",
    "clip_period = 500\n",
    "\n",
    "PATH_TO_MTC_DATA = '/srv/mtc_data'\n",
    "PATH_TO_AUDIO = join(PATH_TO_MTC_DATA, 'tpm-f2020-project/mtc-audio-TRC')\n",
    "PATH_TO_SPLIT_AUDIO = join(PATH_TO_MTC_DATA, 'tpm-f2020-project/mtc-split-wav-files')\n",
    "\n",
    "SPLIT_AUDIO_DIR_CONVENTION = 'length-{}-period-{}'\n",
    "DATA_POINT_DIR_CONVENTION = 'starttime-{}-title-{}'\n",
    "SPLIT_AUDIO_FILE_CONVENTION = 'last-{}.wav'\n",
    "QUESTION_TRUTH_LABELS_CONVENTION = 'tpm-f2020-project/length-{}-period-{}-question_truth_labels.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(join(PATH_TO_MTC_DATA, 'tpm-f2020-project/batches_dirs.pkl'), \"rb\")\n",
    "batches_dirs = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(join(PATH_TO_MTC_DATA, 'tpm-f2020-project/batches_labels.pkl'), \"rb\")\n",
    "batches_labels = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix = []\n",
    "labels_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "for i in range(30, 40):\n",
    "    print(i)\n",
    "    batch_dirs = batches_dirs[i]\n",
    "    batch_labels = batches_labels[i]\n",
    "\n",
    "    for j in range(len(batch_dirs)):\n",
    "        data_point_dir = batch_dirs[j]\n",
    "        label = batch_labels[j]\n",
    "        try:\n",
    "            full_audio = pm.Sound(join(data_point_dir, SPLIT_AUDIO_FILE_CONVENTION.format(0)))\n",
    "\n",
    "            t_end = full_audio.get_end_time()\n",
    "            t_beg_last_500 = t_end - 0.5\n",
    "            t_beg_last_500 = t_beg_last_500 if t_beg_last_500 > 0 else 0\n",
    "            t_beg_last_200 = t_end - 0.2\n",
    "            t_beg_last_200 = t_beg_last_200 if t_beg_last_200 > 0 else 0\n",
    "\n",
    "            last_500 = full_audio.extract_part(from_time=t_beg_last_500, to_time=t_end)\n",
    "            last_200 = full_audio.extract_part(from_time=t_beg_last_200, to_time=t_end)\n",
    "\n",
    "            audio_clips = [full_audio, last_500, last_200]\n",
    "            feature_vals = []\n",
    "\n",
    "            for audio_clip in audio_clips:\n",
    "                sample_freq = audio_clip.sampling_frequency\n",
    "\n",
    "                f0 = calculate_fundemental_frequency(audio_clip)\n",
    "                feature_vals.extend(get_stats(f0, sample_freq))\n",
    "\n",
    "                signal_intensity = calculate_signal_intensity(audio_clip)[:,0]\n",
    "                feature_vals.extend(get_stats(signal_intensity, sample_freq))\n",
    "\n",
    "                jitter = calculate_jitter_of_audio_clip(audio_clip)\n",
    "                feature_vals.append(jitter if not np.isnan(jitter) else 0)\n",
    "\n",
    "                shimmer = calculate_shimmer_of_audio_clip(audio_clip)\n",
    "                feature_vals.append(shimmer if not np.isnan(shimmer) else 0)\n",
    "\n",
    "                mfcc_coeff_vectors = calculate_MFCC_coefficients(audio_clip)\n",
    "                for mfcc_coeff_vector in mfcc_coeff_vectors:\n",
    "                    feature_vals.extend([np.mean(mfcc_coeff_vector), np.std(mfcc_coeff_vector)])\n",
    "\n",
    "                rms = calculate_RMS_frame_energy(audio_clip)\n",
    "                feature_vals.append(rms)\n",
    "\n",
    "            num_pauses, pause_durations, pause_starts, pause_total_length = calculate_pauses(full_audio)\n",
    "            feature_vals.extend([num_pauses, pause_total_length])\n",
    "            feature_vals.extend(get_pause_stats(pause_durations, pause_starts))\n",
    "\n",
    "            zcr = calculate_zero_crossing_rate(full_audio)\n",
    "            feature_vals.append(zcr)\n",
    "\n",
    "            spectral_balance = calculate_spectral_balance(full_audio)\n",
    "            feature_vals.append(spectral_balance if not np.isnan(spectral_balance) else 0)\n",
    "\n",
    "            average_psd = calculate_power_spectral_density(full_audio)\n",
    "            feature_vals.append(np.argmax(average_psd))\n",
    "            feature_vals.append(np.max(average_psd))\n",
    "\n",
    "            data_matrix.append(np.array(feature_vals))\n",
    "            labels_array.append(label)\n",
    "        except Exception as e:\n",
    "            print(e.with_traceback())\n",
    "            \n",
    "f = open(join(PATH_TO_MTC_DATA, 'tpm-f2020-project/data_matrix.pkl'), \"wb\")\n",
    "pickle.dump(data_matrix, f)\n",
    "f.close()\n",
    "\n",
    "f = open(join(PATH_TO_MTC_DATA, 'tpm-f2020-project/labels_array.pkl'), \"wb\")\n",
    "pickle.dump(labels_array, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(join(PATH_TO_MTC_DATA, 'tpm-f2020-project/data_matrix.pkl'), \"rb\")\n",
    "test_matrix = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(join(PATH_TO_MTC_DATA, 'tpm-f2020-project/labels_array.pkl'), \"rb\")\n",
    "test_array = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_matrix = np.array(test_matrix)\n",
    "full_labels_array = np.array(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 194)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data_matrix.shape\n",
    "full_labels_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
